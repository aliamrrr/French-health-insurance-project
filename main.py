import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import seaborn as sns

def process_fraud_data(df):
    df = df[(df['Quantit√© d\'acte - Prestation seule (pas presta. de r√©f.)'] > 0) &
            (df['Montant de la d√©pense - Prestation seule'] > 0)]
    
    df['D√©lai prescription-facturation'] = (
        (df['Ann√©e de remboursement'] - df['Ann√©e de prescription']) * 12 +
        (df['Mois de remboursement'] - df['Mois de prescription'])
    )
    
    remboursements_par_mois = df.groupby(
        ['N¬∞ PS ex√©cutant Statistique', 'Ann√©e de remboursement', 'Mois de remboursement']
    )['Nombre de b√©n√©ficiaires'].sum().reset_index(name='B√©n√©ficiaires par mois')
    df = df.merge(remboursements_par_mois, on=['N¬∞ PS ex√©cutant Statistique', 'Ann√©e de remboursement', 'Mois de remboursement'])
    
    depenses_par_mois = df.groupby(
        ['N¬∞ PS ex√©cutant Statistique', 'Ann√©e de remboursement', 'Mois de remboursement']
    )['Montant de la d√©pense - Prestation seule'].sum().reset_index(name='D√©penses par mois')
    df = df.merge(depenses_par_mois, on=['N¬∞ PS ex√©cutant Statistique', 'Ann√©e de remboursement', 'Mois de remboursement'])
    
    proportion_jeunes = df.groupby('N¬∞ PS ex√©cutant Statistique')['Age du b√©n√©ficiaire'].apply(lambda x: (x < 18).mean())
    df = df.merge(proportion_jeunes.rename('Proportion jeunes'), on='N¬∞ PS ex√©cutant Statistique')
    
    df['Age sup√©rieur √† 18'] = (df['Age du b√©n√©ficiaire'] > 18).astype(int)
    df = df[df['D√©lai prescription-facturation'] <= 8]
    
    prescripteurs_par_etablissement = df.groupby('N¬∞ PS ex√©cutant Statistique')['N¬∞ PS prescripteur Statistique'].nunique().reset_index()
    prescripteurs_par_etablissement.columns = ['N¬∞ PS ex√©cutant Statistique', 'Nombre de prescripteurs']
    df = df.merge(prescripteurs_par_etablissement, on='N¬∞ PS ex√©cutant Statistique', how='left')
    
    prescripteurs_orl = df[df['Libell√© sp√©cialit√©/nat. activit√© du PS prescripteur'] == 'OTO RHINO-LARYNGOLOGIE'] \
        .groupby('N¬∞ PS ex√©cutant Statistique')['N¬∞ PS prescripteur Statistique'].nunique().reset_index()
    prescripteurs_orl.columns = ['N¬∞ PS ex√©cutant Statistique', 'Nombre de prescripteurs ORL']
    df = df.merge(prescripteurs_orl, on='N¬∞ PS ex√©cutant Statistique', how='left')
    
    df['Pourcentage ORL'] = (df['Nombre de prescripteurs ORL'] / df['Nombre de prescripteurs']) * 100
    df['Pourcentage autres'] = 100 - df['Pourcentage ORL']
    
    df = df.drop_duplicates()
    df['Moyenne √¢ge par √©tablissement'] = df.groupby('N¬∞ PS ex√©cutant Statistique')['Age du b√©n√©ficiaire'].transform('mean')
    
    return df

def process_location_data(df1, df2):

    df2['Latitude moyenne'] = (
    (df2['Latitude la plus au nord'] + df2['Latitude la plus au sud']) / 2
        )
    df2['Longitude moyenne'] = (
    (df2['Longitude la plus √† l‚Äôest'] + df2['Longitude la plus √† l‚Äôouest']) / 2
        )

    # Renommer les colonnes pour correspondre aux noms des d√©partements
    departments_benef = df2.rename(columns={
        'Departement': 'D√©partement du b√©n√©ficiaire',
        'Latitude moyenne': 'Latitude b√©n√©ficiaire',
        'Longitude moyenne': 'Longitude b√©n√©ficiaire'
    })
    departments_execut = df2.rename(columns={
        'Departement': "D√©partement d'exercice du PS ex√©cutant",
        'Latitude moyenne': 'Latitude ex√©cutant',
        'Longitude moyenne': 'Longitude ex√©cutant'
    })
    
    print(df2.columns)
    departments_prescripteur = df2.rename(columns={
        'Departement': 'D√©partement du cabinet principal du PS Prescripteur',
        'Latitude moyenne': 'Latitude prescripteur',
        'Longitude moyenne': 'Longitude prescripteur'
    })

    
    # Correction des codes d√©partementaux pour la Corse
    departments_benef.loc[departments_benef['D√©partement du b√©n√©ficiaire'] == '2A', 'D√©partement du b√©n√©ficiaire'] = "200"
    departments_benef.loc[departments_benef['D√©partement du b√©n√©ficiaire'] == '2B', 'D√©partement du b√©n√©ficiaire'] = "201"
    
    departments_execut.loc[departments_execut["D√©partement d'exercice du PS ex√©cutant"] == '2A', "D√©partement d'exercice du PS ex√©cutant"] = "200"
    departments_execut.loc[departments_execut["D√©partement d'exercice du PS ex√©cutant"] == '2B', "D√©partement d'exercice du PS ex√©cutant"] = "201"
    
    departments_prescripteur.loc[departments_prescripteur['D√©partement du cabinet principal du PS Prescripteur'] == '2A', 'D√©partement du cabinet principal du PS Prescripteur'] = "200"
    departments_prescripteur.loc[departments_prescripteur['D√©partement du cabinet principal du PS Prescripteur'] == '2B', 'D√©partement du cabinet principal du PS Prescripteur'] = "201"
    
    # Convertir en entier
    departments_benef['D√©partement du b√©n√©ficiaire'] = departments_benef['D√©partement du b√©n√©ficiaire'].astype(int)
    departments_execut["D√©partement d'exercice du PS ex√©cutant"] = departments_execut["D√©partement d'exercice du PS ex√©cutant"].astype(int)
    departments_prescripteur['D√©partement du cabinet principal du PS Prescripteur'] = departments_prescripteur['D√©partement du cabinet principal du PS Prescripteur'].astype(int)

    # Fusion des donn√©es de localisation
    df1 = df1.merge(departments_benef, on='D√©partement du b√©n√©ficiaire', how='left')
    df1 = df1.merge(departments_execut, on="D√©partement d'exercice du PS ex√©cutant", how='left')
    df1 = df1.merge(departments_prescripteur, on='D√©partement du cabinet principal du PS Prescripteur', how='left')
    
    # Calcul de la distance b√©n√©ficiaire - √©tablissement
    def haversine(lat1, lon1, lat2, lon2):
        R = 6371  # Rayon de la Terre en km
        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2
        c = 2 * np.arcsin(np.sqrt(a))
        return R * c
    
    df1['Distance benef ex (km)'] = haversine(
        df1['Latitude b√©n√©ficiaire'],
        df1['Longitude b√©n√©ficiaire'],
        df1['Latitude ex√©cutant'],
        df1['Longitude ex√©cutant']
    )

    df1['Distance pr etab (km)'] = haversine(
        df1['Latitude prescripteur'],
        df1['Longitude prescripteur'],
        df1['Latitude ex√©cutant'],
        df1['Longitude ex√©cutant']
    )
    
    # Filtrage sur les distances
    df1['Distance benef ex (km)'] = df1['Distance benef ex (km)'].apply(
        lambda x: 0 if x < 50 else x
    )

    # Filtrage sur les distances
    df1['Distance pr etab (km)'] = df1['Distance pr etab (km)'].apply(
        lambda x: 0 if x < 50 else x
    )

    # Calcul de la fr√©quence des grandes distances pour chaque √©tablissement
    df1['Grande distance'] = (df1['Distance benef ex (km)'] > 50).astype(int)
    frequence_dist = df1.groupby('N¬∞ PS ex√©cutant Statistique')['Grande distance'].mean().reset_index()
    frequence_dist.columns = ['N¬∞ PS ex√©cutant Statistique', 'Frequence_dist_suspecte']

    # Normalisation entre 0 et 1
    min_val = frequence_dist['Frequence_dist_suspecte'].min()
    max_val = frequence_dist['Frequence_dist_suspecte'].max()
    frequence_dist['Frequence_dist_suspecte'] = (frequence_dist['Frequence_dist_suspecte'] - min_val) / (max_val - min_val)
    
    df1 = df1.merge(frequence_dist, on='N¬∞ PS ex√©cutant Statistique', how='left')
    
    return df1

def main():
    st.set_page_config(page_title="Application de D√©tection Avanc√©e", layout="wide")
    st.header("üîç Analyse des Comportements Anormaux dans les Donn√©es d'Audioproth√®ses")
    st.markdown("Veuillez t√©l√©verser deux fichiers CSV : votre jeu de donn√©es principal et le fichier de correspondance des r√©gions.")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("T√©l√©versement du Jeu de Donn√©es Principal")
        file1 = st.file_uploader("Choisir le premier fichier CSV", type="csv", key="file1")
        
    with col2:
        st.subheader("T√©l√©versement du Fichier de Correspondance R√©gionale")
        file2 = st.file_uploader("Choisir le second fichier CSV", type="csv", key="file2")

    if file1 is not None and file2 is not None:
        df1 = pd.read_csv(file1)
        df2 = pd.read_csv(file2)

        df1 = process_fraud_data(df1)
        df1 = process_location_data(df1, df2)

        tab1, tab2, tab3 = st.tabs(["Aper√ßu des Donn√©es", "Analyse Avanc√©e", "Visualisations"])

        with tab1:
            st.subheader("üìå Aper√ßu du Jeu de Donn√©es")
            st.write(df1.head())
            
            st.subheader("üìä Statistiques Descriptives")
            st.write(df1.describe())

        with tab2:
            st.header("üö® Tableau de Bord d'Analyse Avanc√©e")
            st.markdown("---")

            st.subheader("üéõÔ∏è S√©lection des Variables")
            all_features = [
                'D√©lai prescription-facturation',
                'B√©n√©ficiaires par mois',
                'D√©penses par mois',
                'Quantit√© d\'acte - Prestation seule (pas presta. de r√©f.)',
                'Montant de la d√©pense - Prestation seule',
                'Proportion jeunes',
                'Age sup√©rieur √† 18',
                'Moyenne √¢ge par √©tablissement',
                'Distance benef ex (km)',
                'Nombre de prescripteurs',
                'Pourcentage ORL',
                'Pourcentage autres',
                'Frequence_dist_suspecte',
                'Distance pr etab (km)'
            ]

            selected_features = st.multiselect(
                "üîß S√©lectionnez les variables √† analyser :",
                all_features,
                default=all_features
            )

            if st.button("üöÄ Lancer l'Analyse"):
                with st.spinner("üîé Analyse en cours..."):
                    st.markdown("---")
                    st.header("üìà R√©sultats de l'Analyse Avanc√©e")

                    df1[selected_features] = df1[selected_features].fillna(df1[selected_features].mean())

                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(df1[selected_features])

                    model = IsolationForest(contamination=0.01, random_state=42)
                    df1['Anomalie'] = model.fit_predict(X_scaled)
                    df1['Score_Anomalie'] = model.decision_function(X_scaled)

                    df1['Anomalie'] = df1['Anomalie'].map({1: 0, -1: 1})

                    st.session_state.anomalies = df1[df1['Anomalie'] == 1]
                    st.session_state.normales = df1[df1['Anomalie'] == 0]

                    st.subheader("üìä R√©sum√© de l'Analyse")
                    col1, col2, col3 = st.columns(3)
                    col1.metric("üíº Total des Transactions", len(df1))
                    col2.metric("‚ö†Ô∏è Anomalies Potentielles", df1['Anomalie'].sum())

                    perte_potentielle = df1[df1['Anomalie'] == 1]['Montant de la d√©pense - Prestation seule'].sum()
                    col3.metric("üí∞ Estimation des Pertes Potentielles", f"‚Ç¨ {perte_potentielle:,.2f}")

                    st.subheader("üîç Caract√©ristiques des Anomalies")
                    anomalies = df1[df1['Anomalie'] == 1]
                    normales = df1[df1['Anomalie'] == 0]

                    st.markdown("**üìä Comparaison des Moyennes**")
                    compare_df = pd.DataFrame({
                        'Normal': normales[selected_features].mean(),
                        'Anomalie': anomalies[selected_features].mean()
                    }).style.format("{:.2f}")
                    st.dataframe(compare_df)

                    st.subheader("üî• Anomalies les Plus Significatives")
                    anomalies_sorted = anomalies.sort_values(by='Score_Anomalie', ascending=True)
                    st.dataframe(anomalies_sorted.head(10)[['N¬∞ PS ex√©cutant Statistique', 'Score_Anomalie'] + selected_features])

                    st.subheader("üìä Corr√©lation entre les Anomalies et les Variables S√©lectionn√©es")
                    correlation_matrix = anomalies[selected_features].corr()

                    plt.figure(figsize=(10, 8))
                    sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", cbar=True, linewidths=0.5)
                    plt.title("Corr√©lation entre les Variables et les Anomalies", fontsize=16)
                    st.pyplot(plt)

        with tab3:
            if 'anomalies' in st.session_state and 'normales' in st.session_state:
                anomalies = st.session_state.anomalies
                normales = st.session_state.normales

                # Cr√©ation des sous-tabs
                sub_tab1, sub_tab2, sub_tab3 = st.tabs(["Indicateurs et comparaisons", "Analyse de r√©gions", "Analyse d'√©tablissements"])

                with sub_tab1:  # Indicateurs et comparaisons
                    st.write("Comparaison du D√©lai prescription-facturation")
                    mean_anomalies = anomalies['D√©lai prescription-facturation'].mean()
                    mean_normales = normales['D√©lai prescription-facturation'].mean()
                    categories = ['Anomalies', 'Normales']
                    means = [mean_anomalies, mean_normales]

                    fig, ax = plt.subplots(figsize=(10, 6))
                    colors = ['#1f77b4', '#ff7f0e']
                    bars = ax.barh(categories, means, color=colors, edgecolor='black', linewidth=1.2)

                    for bar in bars:
                        ax.text(bar.get_width() + 0.05, bar.get_y() + bar.get_height()/2,
                                f'{bar.get_width():.2f}', va='center', ha='left', fontsize=12, color='black')

                    ax.set_xlabel("Moyenne du D√©lai prescription-facturation", fontsize=14)
                    ax.set_ylabel("Cat√©gories", fontsize=14)
                    ax.set_title("Comparaison des Moyennes du D√©lai prescription-facturation", fontsize=16, fontweight='bold')
                    ax.set_facecolor('whitesmoke')
                    for spine in ax.spines.values():
                        spine.set_linewidth(1.5)
                        spine.set_color('gray')

                    st.pyplot(fig)
                    
                    
                    st.write("Distribution des Distances Beneficiare - etablisssement dans les Anomalies")
                    fig, ax = plt.subplots(figsize=(10, 6))
                    sns.histplot(anomalies['Distance pr etab (km)'], bins=30, kde=True, color='orange', ax=ax)
                    ax.set_title("Distribution des Distances (Anomalies)", fontsize=16)
                    ax.set_xlabel('Distance pr etab (km)', fontsize=12)
                    ax.set_ylabel("Fr√©quence", fontsize=12)

                    st.pyplot(fig)

                                        
                                        
                    st.write("Distribution des Distances Prescripteur - etablissement dans les Anomalies")
                    fig, ax = plt.subplots(figsize=(10, 6))
                    sns.histplot(anomalies['Distance benef ex (km)'], bins=30, kde=True, color='orange', ax=ax)
                    ax.set_title("Distribution des Distances (Anomalies)", fontsize=16)
                    ax.set_xlabel("Distance benef ex (km)", fontsize=12)
                    ax.set_ylabel("Fr√©quence", fontsize=12)

                    st.pyplot(fig)


                    st.write("Top 3 √âtablissements par Fr√©quence de Distances Suspectes")

                    # Top 3 dans les anomalies
                    top3_anomalies = (
                        anomalies.groupby('N¬∞ PS ex√©cutant Statistique')['Frequence_dist_suspecte']
                        .mean()
                        .nlargest(3)
                        .reset_index()
                    )
                    top3_anomalies['Cat√©gorie'] = 'Anomalies'

                    # Top 3 dans les normales (en s'assurant qu'ils sont diff√©rents de ceux dans anomalies)
                    top3_normales = (
                        normales[~normales['N¬∞ PS ex√©cutant Statistique'].isin(top3_anomalies['N¬∞ PS ex√©cutant Statistique'])]
                        .groupby('N¬∞ PS ex√©cutant Statistique')['Frequence_dist_suspecte']
                        .mean()
                        .nlargest(3)
                        .reset_index()
                    )
                    top3_normales['Cat√©gorie'] = 'Normales'

                    # Combiner les deux DataFrames
                    top3 = pd.concat([top3_anomalies, top3_normales])

                    # Visualisation
                    fig, ax = plt.subplots(figsize=(12, 8))
                    sns.barplot(
                        data=top3,
                        y='N¬∞ PS ex√©cutant Statistique',
                        x='Frequence_dist_suspecte',
                        hue='Cat√©gorie',
                        palette={'Anomalies': '#ff7f0e', 'Normales': '#1f77b4'},
                        edgecolor='black'
                    )
                    
                    ax.set_xlabel("Fr√©quence de Distances Suspectes", fontsize=14)
                    ax.set_ylabel("√âtablissements", fontsize=14)
                    ax.set_title("Top 3 √âtablissements par Fr√©quence de Distances Suspectes", fontsize=16, fontweight='bold')
                    ax.set_facecolor('whitesmoke')
                    ax.legend(title='Cat√©gorie')

                    for spine in ax.spines.values():
                        spine.set_linewidth(1.5)
                        spine.set_color('gray')

                    st.pyplot(fig)


                with sub_tab2:  # Analyse de r√©gions
                    st.write("R√©partition des D√©partements dans les Anomalies")
                    top_departments = anomalies['D√©partement d\'exercice du PS ex√©cutant'].value_counts().head(5)

                    fig, ax = plt.subplots(figsize=(8, 6))
                    ax.pie(top_departments, labels=top_departments.index, autopct='%1.1f%%', startangle=90, wedgeprops={'width': 0.3})
                    centre_circle = plt.Circle((0, 0), 0.50, color='white', fc='white', lw=0)
                    ax.add_artist(centre_circle)
                    ax.set_title("R√©partition des D√©partements (Anomalies)", fontsize=14)

                    st.pyplot(fig)

                    # Mapping des d√©partements vers les r√©gions
                    departement_to_region = {
                        '01': 'Auvergne-Rh√¥ne-Alpes', '02': 'Hauts-de-France', '03': 'Auvergne-Rh√¥ne-Alpes', '04': 'Provence-Alpes-C√¥te d\'Azur',
                        '05': 'Provence-Alpes-C√¥te d\'Azur', '06': 'Provence-Alpes-C√¥te d\'Azur', '07': 'Auvergne-Rh√¥ne-Alpes', '08': 'Grand Est',
                        '09': 'Occitanie', '10': 'Grand Est', '11': 'Occitanie', '12': 'Occitanie', '13': 'Provence-Alpes-C√¥te d\'Azur', '14': 'Normandie',
                        '15': 'Auvergne-Rh√¥ne-Alpes', '16': 'Nouvelle-Aquitaine', '17': 'Nouvelle-Aquitaine', '18': 'Centre-Val de Loire', '19': 'Nouvelle-Aquitaine',
                        '20': 'Corse', '21': 'Bourgogne-Franche-Comt√©', '22': 'Bretagne', '23': 'Nouvelle-Aquitaine', '24': 'Nouvelle-Aquitaine', '25': 'Bourgogne-Franche-Comt√©',
                        '26': 'Auvergne-Rh√¥ne-Alpes', '27': 'Normandie', '28': 'Centre-Val de Loire', '29': 'Bretagne', '30': 'Occitanie', '31': 'Occitanie',
                        '32': 'Occitanie', '33': 'Nouvelle-Aquitaine', '34': 'Occitanie', '35': 'Bretagne', '36': 'Centre-Val de Loire', '37': 'Centre-Val de Loire',
                        '38': 'Auvergne-Rh√¥ne-Alpes', '39': 'Bourgogne-Franche-Comt√©', '40': 'Nouvelle-Aquitaine', '41': 'Centre-Val de Loire', '42': 'Auvergne-Rh√¥ne-Alpes',
                        '43': 'Auvergne-Rh√¥ne-Alpes', '44': 'Pays de la Loire', '45': 'Centre-Val de Loire', '46': 'Occitanie', '47': 'Nouvelle-Aquitaine',
                        '48': 'Occitanie', '49': 'Pays de la Loire', '50': 'Normandie', '51': 'Grand Est', '52': 'Grand Est', '53': 'Pays de la Loire', '54': 'Grand Est',
                        '55': 'Grand Est', '56': 'Bretagne', '57': 'Grand Est', '58': 'Bourgogne-Franche-Comt√©', '59': 'Hauts-de-France', '60': 'Hauts-de-France',
                        '61': 'Normandie', '62': 'Hauts-de-France', '63': 'Auvergne-Rh√¥ne-Alpes', '64': 'Nouvelle-Aquitaine', '65': 'Occitanie', '66': 'Occitanie',
                        '67': 'Grand Est', '68': 'Grand Est', '69': 'Auvergne-Rh√¥ne-Alpes', '70': 'Bourgogne-Franche-Comt√©', '71': 'Bourgogne-Franche-Comt√©', '72': 'Pays de la Loire',
                        '73': 'Auvergne-Rh√¥ne-Alpes', '74': 'Auvergne-Rh√¥ne-Alpes', '75': '√éle-de-France', '76': 'Normandie', '77': '√éle-de-France', '78': '√éle-de-France',
                        '79': 'Nouvelle-Aquitaine', '80': 'Hauts-de-France', '81': 'Occitanie', '82': 'Occitanie', '83': 'Provence-Alpes-C√¥te d\'Azur', '84': 'Provence-Alpes-C√¥te d\'Azur',
                        '85': 'Pays de la Loire', '86': 'Nouvelle-Aquitaine', '87': 'Nouvelle-Aquitaine', '88': 'Grand Est', '89': 'Bourgogne-Franche-Comt√©', '90': 'Bourgogne-Franche-Comt√©',
                        '91': '√éle-de-France', '92': '√éle-de-France', '93': '√éle-de-France', '94': '√éle-de-France', '95': '√éle-de-France', '96': 'Outre-mer', '97': 'Outre-mer',
                        '98': 'Outre-mer', '99': 'Outre-mer'
                    }

                    # Comptage des d√©partements les plus fr√©quents dans anomalies
                    top_departments = anomalies['D√©partement d\'exercice du PS ex√©cutant'].value_counts().head(10)

                    # Mappage des d√©partements vers les r√©gions
                    top_departments_regions = top_departments.index.astype(str).map(departement_to_region)

                    # Comptage des r√©gions les plus fr√©quentes dans anomalies (apr√®s mappage)
                    region_counts = top_departments_regions.value_counts()

                    # Mappage des d√©partements aux r√©gions
                    department_to_region = top_departments.index.to_series().map(departement_to_region)

                    # Calcul de la somme des pourcentages des d√©partements dans chaque r√©gion
                    region_percentage = top_departments.groupby(top_departments_regions).sum() / top_departments.sum() * 100

                    # Cr√©ation du barh chart pour les r√©gions
                    plt.figure(figsize=(10, 6))

                    # Choisir un jeu de couleurs styl√©
                    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']

                    # Tracer le graphique en barh
                    bars = region_percentage.plot(kind='barh', color=colors, edgecolor='black', linewidth=1.2)

                    # Ajouter des labels sur les barres
                    for index, value in enumerate(region_percentage):
                        # Ajouter l'√©tiquette dans la barre, avec la somme des pourcentages des d√©partements
                        plt.text(value + 0.1, index, f'{value:.1f}%', va='center', ha='left', fontsize=12, color='black')

                    # Ajouter des titres et des labels
                    plt.xlabel("Somme des pourcentages des d√©partements", fontsize=14)
                    plt.ylabel("R√©gions", fontsize=14)
                    plt.title("R√©partition des r√©gions les plus fr√©quentes dans les anomalies", fontsize=16, fontweight='bold')

                    # Personnaliser les axes et l'apparence
                    plt.xticks(fontsize=12)
                    plt.yticks(fontsize=12)

                    # Ajouter un fond et des bordures stylis√©es
                    plt.gca().set_facecolor('whitesmoke')
                    for spine in plt.gca().spines.values():
                        spine.set_linewidth(1.5)
                        spine.set_color('gray')

                    st.pyplot()

                
                with sub_tab3:
                    etablissement_anomalie_id = anomalies['N¬∞ PS ex√©cutant Statistique'].value_counts().idxmax()
                    etablissement_normal_id = normales['N¬∞ PS ex√©cutant Statistique'].value_counts().idxmax()

                    # Filtrer les donn√©es pour ces deux √©tablissements
                    anomalies_etablissement = anomalies[anomalies['N¬∞ PS ex√©cutant Statistique'] == etablissement_anomalie_id]
                    normales_etablissement = normales[normales['N¬∞ PS ex√©cutant Statistique'] == etablissement_normal_id]

                    # Calculer les remboursements totaux par mois pour anomalies et normales
                    anomalies_mois = anomalies_etablissement.groupby(['Ann√©e de remboursement', 'Mois de remboursement'])['D√©penses par mois'].sum().reset_index()
                    normales_mois = normales_etablissement.groupby(['Ann√©e de remboursement', 'Mois de remboursement'])['D√©penses par mois'].sum().reset_index()

                    # Tracer le graphique
                    fig, ax = plt.subplots(figsize=(12, 6))  # Cr√©er un objet figure et axe
                    sns.lineplot(data=anomalies_mois, x='Mois de remboursement', y='D√©penses par mois', label=f'Anomalies ({etablissement_anomalie_id})', color='red', marker='o', ax=ax)
                    sns.lineplot(data=normales_mois, x='Mois de remboursement', y='D√©penses par mois', label=f'Normales ({etablissement_normal_id})', color='blue', marker='o', ax=ax)

                    # Ajouter des d√©tails au graphique
                    ax.set_title(f'D√©penses par mois : {etablissement_anomalie_id} (Anomalies) vs {etablissement_normal_id} (Normales)')
                    ax.set_xlabel('Mois')
                    ax.set_ylabel('D√©penses')
                    ax.legend(title='Cat√©gorie', loc='upper left')
                    ax.set_xticklabels(ax.get_xticks(), rotation=45)
                    ax.grid(True)

                    st.pyplot(fig)

                    # Affichage des √©tablissements s√©lectionn√©s pour confirmation
                    st.write(f"√âtablissement le plus fr√©quent dans les anomalies : {etablissement_anomalie_id}")
                    st.write(f"√âtablissement le plus fr√©quent dans les normales : {etablissement_normal_id}")



if __name__ == "__main__":
    main()

